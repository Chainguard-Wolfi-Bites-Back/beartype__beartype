#!/usr/bin/env python3
# --------------------( LICENSE                           )--------------------
# Copyright (c) 2014-2020 Cecil Curry.
# See "LICENSE" for further details.

'''
**Beartype caching utilities.**

This private submodule implements supplementary cache-specific utility
functions required by various :mod:`beartype` facilities, including callables
generated by the :func:`beartype.beartype` decorator.

This private submodule is *not* intended for importation by downstream callers.
'''

# ....................{ IMPORTS                           }....................
import inspect
from beartype.cave import CallableTypes
from functools import wraps

# ....................{ COSTANTS                          }....................
SENTINEL = object()
'''
Sentinel object of arbitrary value.

This object is internally leveraged by various utility functions to identify
erroneous and edge-case input (e.g., iterables of insufficient length).
'''

# ....................{ DECORATORS                        }....................
#FIXME: Unit test us up.
def callable_cached(func: CallableTypes) -> CallableTypes:
    '''
    **Memoize** (i.e., efficiently cache and return all previously returned
    values of the passed callable rather than inefficiently recalling that
    callable) the passed callable.

    Specifically, this decorator (in order):

    #. Creates a local dictionary mapping parameters passed to this callable
       with the values returned by this callable when passed those parameters.
    #. Creates and returns a closure transparently wrapping this callable with
       memoization. Specifically, this wrapper (in order):

       #. Tests whether this callable has already been called at least once
          with the passed parameters by lookup of those parameters in this
          dictionary.
       #. If this is the case, this wrapper efficiently returns the value
          previously returned by this callable when passed those parameters by
          lookup of that value in this dictionary.
       #. Else, this wrapper:

          #. Calls that callable with those parameters.
          #. Caches the value returned by that call with those parameters in
             this dictionary.
          #. Returns this value.

    Caveats
    ----------
    **All parameters passed to the decorated callable must be hashable** (i.e.,
    immutable). Ergo, this decorator *cannot* memoize callables either
    accepting or returning mutable containers (e.g., `list`, `dict`).

    **Maximize efficiency by only calling the decorated callable with
    positional arguments.** While calling this callable with keyword arguments
    is supported, doing so reduces the efficiency of the memoization performed
    by this decorator -- which is the whole point of this decorator, after all.

    **Order of keyword arguments passed to the decorated callable is
    significant.** This decorator re-caches return values produced by calls to
    the decorated callable when passed the same keyword arguments in different
    orders (e.g., ``muh_func(muh_kw=0, mah_kw=1)`` and ``muh_func(mah_kw=1,
    muh_kw=0)``, cached as two distinct calls by this decorator despite these
    calls ultimately receiving the same arguments).

    Implementation
    ----------
    **This decorator is intentionally not implemented in terms of the stdlib**
    :func:`functools.lru_cache` **decorator,** as that decorator is inefficient
    in the special case of unbounded caching with ``maxsize=None``, mostly as
    that decorator insists on unconditionally recording irrelevant statistics
    such as cache misses and hits. While bounding the number of cached values
    is advisable in the general case (e.g., to avoid exhausting memory merely
    for optional caching), the callable parameters and return values cached by
    this package are sufficiently small in size to render bounding irrelevant.

    Consider the :func:`beartype._decor.pep484.p484test.is_typing` function,
    for example. Each call to that function only accepts a single class and
    returns a boolean. Under conservative assumptions of 4 bytes of storage per
    class reference and 4 byte of storage per boolean reference, each call to
    that function requires caching at most 8 bytes of storage. Again, under
    conservative assumptions of at most 1024 unique type annotations for the
    average downstream consumer, memoizing that function in full requires at
    most 1024 * 8 == 8096 bytes or ~8Kb of storage. Clearly, 8Kb of overhead is
    sufficiently negligible to obviate any space concerns that would warrant an
    LRU cache in the first place.

    Parameters
    ----------
    func : CallableTypes
        Callable to be memoized.

    Returns
    ----------
    CallableTypes
        Closure wrapping this callable with memoization..
    '''
    assert callable(func), '{!r} not callable.'.format(func)

    # Dictionary mapping a tuple of all flattened parameters passed to each
    # prior call of the decorated callable with the value returned by that
    # call. This is the principal cache with which this callable is memoized.
    params_flat_to_return_value = {}

    # get() method of this dictionary, localized for efficiency.
    params_flat_to_return_value_get = params_flat_to_return_value.get

    # Signature of the decorated callable.
    func_sig = inspect.signature(func)

    # Dictionary mapping from the name of each parameters accepted by the
    # decorated callable to the 0-based index of that parameter in the
    # signature of this callable.
    param_name_to_index = {
        param_name: param_index
        for param_index, param_name in enumerate(func_sig.parameters.keys())
    }

    @wraps(func)
    def _callable_cached(*args, **kwargs):
        '''
        Memoized variant of the {}() callable.

        Raises
        ----------
        TypeError
            If any parameter passed to this callable is **unhashable** (i.e.,
            mutable).

        See Also
        ----------
        :func:`callable_cached`
            Further details.
        '''.format(func.__name__)

        # Flatten the passed tuple of positional arguments and dictionary of
        # keyword arguments into a single tuple containing both positional and
        # keyword arguments. To minimize space consumption, this tuple contains
        # these arguments as is with *NO* nested containers.
        #
        # For example, when a decorated callable with signature:
        #     def muh_func(muh_arg1, muh_arg2, muh_arg3, muh_arg4)
        # ...is called as:
        #     muh_func('a', 'b', muh_arg3=0, muh_arg4=1)
        # ...this wrapper receives
        #    *args = ('a', 'b')
        #    *kwargs = {'muh_arg3': 0, 'muh_arg4': 1}
        # ...which the following logic flattens into:
        #    params_flat = ('a', 'b', 0, 1)
        #
        # If one or more keyword arguments are passed...
        if kwargs:
            # Convert the passed tuple of positional arguments into a list.
            params_flat = list(args)

            # For the name and value of each passed keyword argument...
            for kwarg_name, kwarg_value in kwargs.items():
                # Convert this keyword argument into a positional argument by
                # setting the 0-based index of this argument when passed as a
                # positional argument in this list to this value.
                params_flat[param_name_to_index[kwarg_name]] = kwarg_value

            # Convert this list back into a tuple.
            params_flat = tuple(params_flat)
        # Else, only positional arguments are passed. In this case, reuse this
        # tuple of such arguments as is.
        else:
            params_flat = args

        # If passed only a single parameter, minimize space consumption by
        # reducing this tuple of a single parameter into that parameter itself.
        if len(params_flat) == 1:
            params_flat = params_flat[0]

        # Value returned by a prior call to the decorated callable when passed
        # these parameters *OR* the sentinel placeholder otherwise (i.e., if
        # this callable has yet to be called with these parameters).
        #
        # Note that this call raises a "TypeError" exception if any item of
        # this flattened tuple is unhashable.
        return_value = params_flat_to_return_value_get(params_flat, SENTINEL)

        # If this callable has already been called with these parameters,
        # return the value returned by that prior call.
        if return_value is not SENTINEL:
            return return_value
        # Else, this callable has yet to be called with these parameters.

        # Call this parameter with these parameters and cache the value
        # returned by this call to these parameters.
        return_value = params_flat_to_return_value[params_flat] = func(
            *args, **kwargs)

        # Return this value.
        return return_value

    # Return this wrapper.
    return _callable_cached
